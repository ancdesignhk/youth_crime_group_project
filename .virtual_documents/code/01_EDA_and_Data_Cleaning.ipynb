


# import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns






# read demographic data
# demo = pd.read_excel('../data/combined_state_demo_data_2016_2022.xlsx', sheet_name = 'Data')
demo = pd.read_csv('../data/combined_state_demo_data_2016_2022.csv')
# check for missing values and print the shape
print(demo.isna().sum())
print(demo.shape)
demo.head()


# read crime data
crime = pd.read_csv('../data/transformed_crime_data.csv')
# rename the 'data_year' column to 'year' and update column names to lowercase with underscores
crime.columns = crime.columns.str.lower().str.replace(' ', '_')
crime.rename(columns={'data_year': 'year'}, inplace=True)
# check for missing values and print the shape
print(crime.isna().sum())
print(crime.shape)
crime.head()


# read youth data
youth = pd.read_csv('../data/youth data.csv')
# update column names to lowercase with underscores
youth.columns = youth.columns.str.lower().str.replace(' ', '_')

print(youth.isna().sum())
print(youth.shape)
youth.head()





# merge demographic and crime data
demo_crime = pd.merge(left = demo, right = crime, how = 'left', left_on = ['state','year'], right_on = ['state','year'])

print(demo_crime.shape)
demo_crime.head()


# merge youth data
combined = pd.merge(left = demo_crime, right = youth, how = 'left', left_on = ['state','year'], right_on = ['state','year'])



# combining crime-related columns to create a new 'total_ crime_count' column
# summing up 'crimes_against_society', 'fraud_and_other_financial_crimes', 'property_crime', and 'violent_crime' columns

# ensuring we handle any missing values during summation by filling NaN with 0 temporarily
combined['total_crime_count'] = combined[['crimes_against_society', 
                           'fraud_and_other_financial_crimes', 
                           'property_crime', 
                           'violent_crime']].fillna(0).sum(axis=1)

# first few rows to confirm the new 'total_ crime_count' column
combined[['state', 'year', 'crimes_against_society', 'fraud_and_other_financial_crimes', 
      'property_crime', 'violent_crime', 'total_crime_count']].head()

# save combined dataframe as .csv
combined.to_csv('../data/state_demo_crime_youth_data_combined.csv')

print(combined.shape)
print(combined.isna().sum())
combined.head()








# drop offender_age
combined.drop(columns = ['offender_age'],
              inplace = True)

print(combined.shape)
combined.head()








# check data types
combined.dtypes


# fix objects
combined['black_pop'] = combined['black_pop'].astype(str).str.replace('<','').astype(float)
combined['native_pop'] = combined['native_pop'].astype(str).str.replace('<','').astype(float)
combined['islander_pop'] = combined['islander_pop'].astype(str).str.replace('<','').astype(float)

combined.head()


# check data types
combined.dtypes





# check population data for 2020
combined[['year','total_pop','white_pop','black_pop',
          'hispanic_pop','asian_pop','native_pop',
          'islander_pop','multi_race_pop']].loc[combined['year'] == 2020]


# fill missing 2020 data with average of 2019 and 2021 data
combined.head()

for row in range(len(combined)):
    if combined.loc[row, 'year'] == 2020:
        combined.loc[row,'total_pop'] = (np.abs(combined['total_pop'][row + 1]) + np.abs(combined['total_pop'][row - 1])) / 2
        combined.loc[row,'white_pop'] = (np.abs(combined['white_pop'][row + 1]) + np.abs(combined['white_pop'][row - 1])) / 2
        combined.loc[row,'black_pop'] = (np.abs(combined['black_pop'][row + 1]) + np.abs(combined['black_pop'][row - 1])) / 2
        combined.loc[row,'hispanic_pop'] = (np.abs(combined['hispanic_pop'][row + 1]) + np.abs(combined['hispanic_pop'][row - 1])) / 2
        combined.loc[row,'asian_pop'] = (np.abs(combined['asian_pop'][row + 1]) + np.abs(combined['asian_pop'][row - 1])) / 2
        combined.loc[row,'native_pop'] = (np.abs(combined['native_pop'][row + 1]) + np.abs(combined['native_pop'][row - 1])) / 2
        combined.loc[row,'islander_pop'] = (np.abs(combined['islander_pop'][row + 1]) + np.abs(combined['islander_pop'][row - 1])) / 2
        combined.loc[row,'multi_race_pop'] = (np.abs(combined['multi_race_pop'][row + 1]) + np.abs(combined['multi_race_pop'][row - 1])) / 2

combined.head()    


# check population data for 2020

combined[['year','total_pop','white_pop','black_pop',
          'hispanic_pop','asian_pop','native_pop',
          'islander_pop','multi_race_pop']].loc[combined['year'] == 2020]





# Convert % columns to rates
print(f"Poverty Rate min BEFORE: {combined['poverty_rate'].min()}")
combined['poverty_rate'] = combined['poverty_rate'] / 100
print(f"Poverty Rate min AFTER: {combined['poverty_rate'].min()}")
print("=" * 30)

print(f"Unemployment Rate min BEFORE: {combined['unemployment_rate'].min()}")
combined['unemployment_rate'] = combined['unemployment_rate'] / 100
print(f"Unemployment Rate min AFTER: {combined['unemployment_rate'].min()}")
print("=" * 30)

print(f"Unemployed 15 Weeks Rate min BEFORE: {combined['unemployed_15_weeks'].min()}")
combined['unemployed_15_weeks'] = combined['unemployed_15_weeks'] / 100
print(f"Unemployed 15 Weeks Rate min AFTER: {combined['unemployed_15_weeks'].min()}")
print("=" * 30)

print(f"Labor Force Participation Rate min BEFORE: {combined['labor_force_participation_rate'].min()}")
combined['labor_force_participation_rate'] = combined['labor_force_participation_rate'] / 100
print(f"Labor Force Participation Rate min AFTER: {combined['labor_force_participation_rate'].min()}")
print("=" * 30)

print(f"High School+ Graduation Rate min BEFORE: {combined['hs_grad_rate'].min()}")
combined['hs_grad_rate'] = combined['hs_grad_rate'] / 100
print(f"High School+ Graduation Rate min AFTER: {combined['hs_grad_rate'].min()}")
print("=" * 30)

print(f"Bachelors+ Graduation Rate min BEFORE: {combined['bachelors_grad_rate'].min()}")
combined['bachelors_grad_rate'] = combined['bachelors_grad_rate'] / 100
print(f"Bachelors+ Graduation Rate min AFTER: {combined['bachelors_grad_rate'].min()}")
print("=" * 30)

combined.head()






# check nulls
print(combined.shape)
combined.isnull().sum()


# replace NaN in native_pop and islander_pop with 0
# these were states that didn't report having a specific pop
combined['black_pop'] = combined['black_pop'].fillna(0)
combined['native_pop'] = combined['native_pop'].fillna(0)
combined['islander_pop'] = combined['islander_pop'].fillna(0)

print(f"black_pop null count: {combined['black_pop'].isnull().sum()}")
print(f"native_pop null count: {combined['native_pop'].isnull().sum()}")
print(f"islander_pop null count: {combined['islander_pop'].isnull().sum()}")





youth_not_in_school_null = combined[combined['youth_not_in_school'].isnull()]
youth_not_in_school_null.head()


# fill missing values in 'youth_columns' by taking the mean for each state
youth_columns = ['youth_not_in_school', 'youth_in_foster_care', 'youth_living_in_poverty']

# group-based mean imputation for each column within each state
for column in youth_columns:
    combined[column] = combined.groupby('state')[column].transform(lambda x: x.fillna(x.mean()))
combined.head()







# distribution of 'total_crime_count'
plt.figure(figsize=(10, 6))
sns.histplot(combined['total_crime_count'], kde=True, bins=30)
plt.title('Distribution of Total Crime Count')
plt.xlabel('Total Crime Count')
plt.ylabel('Frequency')





# Log transformation to address right-skewness in 'total_crime_count' 
# apply log transformation (adding a small constant to avoid log(0))
combined['log_total_crime_count'] = np.log1p(combined['total_crime_count'])

# distribution of log-transformed 'total_crime_count'
plt.figure(figsize=(10, 6))
sns.histplot(combined['log_total_crime_count'], kde=True, bins=30)
plt.title('Log-Transformed Distribution of Total Crime Count')
plt.xlabel('Log of Total Crime Count')
plt.ylabel('Frequency')
plt.show()




